# ProcessMiner Demo Presentation - Full Slide Content

**Audience:** Senior Decision Makers (Banking)
**Duration:** 45 minutes
**Total Slides:** 15 slides (excluding backup)

---

# McKINSEY SLIDE PRINCIPLES APPLIED

This deck follows McKinsey's core presentation principles:

## 1. The Pyramid Principle (Barbara Minto)
- **Lead with the answer:** Each slide title states the conclusion first
- **Support with evidence:** Body content proves the title statement
- **Top-down communication:** Reader gets the key message from the title alone

## 2. Action Titles (Not Descriptive Labels)
Every slide title is a **complete sentence** that states the takeaway:
- âŒ Bad: "Process Documentation Challenges"
- âœ… Good: "Process documentation takes 4-6 weeks because SMEs must write from scratch"

## 3. SCQA Framework (Situation-Complication-Question-Answer)
Phase 1 follows the SCQA structure:
- **Situation:** Transformation programmes require process documentation
- **Complication:** Current approaches take 4-6 weeks and produce incomplete outputs
- **Question:** How can we capture process knowledge efficiently?
- **Answer:** AI drafts documentation, SMEs validate â€” reducing effort by 70%+

## 4. One Message Per Slide
Each slide conveys **one core idea**. The body content exists solely to prove the title.

## 5. MECE Structure
Categories are Mutually Exclusive (no overlaps) and Collectively Exhaustive (no gaps).

## 6. Ghost Deck Test
Read only the slide titles in sequence â€” they should tell a complete, logical story:
1. "Process documentation takes 4-6 weeks because SMEs write from scratch â€” and ChatGPT can't fix this"
2. "Flipping the model â€” AI drafts, SMEs validate â€” reduces effort by 70%+ while improving quality"
3. "Six specialised agents deliver end-to-end transformation capability"
4. "This demo shows methodology and output quality â€” focus on what's produced, not the CLI"
5. [Demo slides support the live demonstration with specific process example]
6. "BMAD provides the framework; banking processes are the first of many applications"
7. "Three actions: Flip the burden, orchestrate expertise, build for regulation"

---

# PHASE 1: THE BUSINESS PROBLEM (Slides 1-3)

---

## Slide 1: Title + The Challenge

### McKinsey Principle Applied
**Action Title:** States the problem and its cause in one sentence
**SCQA Position:** Situation (context) + Complication (the problem)
**Pyramid:** Lead with the key insight â€” 4-6 weeks is the attention-grabbing data point

### Formatting Guidance
- **Layout:** 60/40 split â€” title block left, challenge panel right
- **Background:** Deep blue (#1a365d) gradient on left, white on right
- **Title font:** 48pt bold white on blue background
- **Challenge panel:** Light gray background (#f7fafc) with shadow border
- **Pain points:** Use icon + text pairs, 18pt, vertically stacked
- **Action title position:** Top of right panel, full sentence, bold

---

### LEFT PANEL (60%)

**Product Name:**
# ProcessMiner

**Descriptor:**
AI-Powered Process Transformation

---

### RIGHT PANEL (40%)

**ACTION TITLE (Bold, 24pt, top of panel):**
## Process documentation takes 4-6 weeks because SMEs must write from scratch â€” and uploading DTPs to ChatGPT doesn't fix this

**Supporting Evidence (proves the title):**

**The 4-6 week problem stems from four root causes:**

| Root Cause | Why It Matters |
|------------|----------------|
| **Scattered documentation** | Knowledge lives in outdated Word docs, emails, and people's heads â€” no single source of truth |
| **SME time scarcity** | Experts are your most valuable and least available people â€” writing competes with their core job |
| **Business-IT translation gap** | Even complete documentation rarely translates into specifications IT can act upon |
| **ChatGPT â‰  solution** | Uploading DTPs gives answers based on *documented* process, not *actual* process â€” can't identify gaps or validate reality |

**Key Data Point (callout box):**
> **4-6 weeks** per process Ã— dozens of processes = transformation programmes delayed by months before they start

---

### Speaker Notes

> **Opening approach:** Start by asking the room this question directly. Pause for responses. Most will say "weeks" or "we honestly don't track it." Some may admit processes are never fully documented.
>
> **Key insight to land:** This isn't a documentation problem â€” it's a knowledge extraction problem. The knowledge exists in your SMEs' heads. The challenge is getting it out efficiently.
>
> **Transition:** "What if we could flip this equation entirely?"

---

## Slide 2: The Solution â€” Flip the Burden

### McKinsey Principle Applied
**Action Title:** States the solution AND the quantified result
**SCQA Position:** Answer (the recommendation with evidence)
**Pyramid:** Title contains the "so what" â€” body proves it with data
**One Message:** The single idea is "flip the burden" â€” everything else supports this

### Formatting Guidance
- **Layout:** Top/bottom split â€” comparison table top (55%), KPI cards bottom (45%)
- **Background:** Clean white
- **Table:** Three-column comparison (Traditional | ChatGPT | ProcessMiner)
- **KPI cards:** Three equal-width cards with large numbers and supporting text
- **KPI card style:** White cards with subtle shadow, teal (#319795) accent border on top
- **Action title:** Full sentence at top of slide, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## Flipping the model â€” AI drafts, SMEs validate â€” reduces effort by 70%+ while improving documentation quality to 90%+

---

### TOP SECTION: The Evidence

**Subheading:**
*Three approaches compared: Traditional, ChatGPT with DTPs, and ProcessMiner*

**Comparison Table:**

| Aspect | Traditional Approach | "Upload DTP to ChatGPT" | ProcessMiner Approach |
|--------|---------------------|------------------------|----------------------|
| **Knowledge source** | SME writes from scratch | Existing (often outdated) docs | SME-validated, current reality |
| **Captures actual vs documented** | Depends on SME diligence | âŒ Only what's written | âœ… Elicits tribal knowledge |
| **Identifies gaps** | If SME remembers | âŒ No â€” assumes docs are complete | âœ… Structured validation |
| **Time per process** | 4-6 weeks | Minutes (but wrong answers) | 2-3 sessions of 30 minutes |
| **Output format** | Single Word document | Unstructured chat responses | 5+ documents at multiple altitudes |
| **Compliance mapping** | Manual, often incomplete | âŒ No regulatory awareness | Built-in regulatory frameworks |
| **Traceability** | Inconsistent or absent | âŒ None â€” conversations disappear | Full audit trail with unique IDs |
| **SME validation** | Assumed, rarely verified | âŒ None â€” AI just repeats docs | âœ… Built into every step |

**Callout Box (red border, light red background):**
> âš ï¸ **The "Upload DTP to ChatGPT" Trap**
>
> It's tempting to think: "We have DTPs â€” just upload them to ChatGPT and ask questions." Here's why that fails:
>
> 1. **DTPs describe the designed process, not the actual process.** Every operations team knows reality diverges from documentation. ChatGPT can't know about the workaround in Step 7 that everyone uses.
>
> 2. **DTPs don't capture pain points.** The document says "categorise complaint" â€” it doesn't say "this step takes 45 minutes because the dropdown has 200 options and no search."
>
> 3. **ChatGPT doesn't validate.** It will confidently give you answers based on a DTP that was last updated in 2019. It has no way to know the process changed.
>
> 4. **No audit trail.** When transformation decisions are challenged, "ChatGPT told us" is not an acceptable answer for a regulated institution.
>
> **ProcessMiner uses existing documentation as a *starting point* for SME validation â€” not as the source of truth.**

---

### BOTTOM SECTION: Measured Results

**Section Header:**
#### Pilot Results

**Three KPI Cards:**

**Card 1:**
### 70%+
**Reduction in SME Time**

A 30-minute structured session captures the equivalent of 4+ hours of traditional documentation effort. SMEs validate AI-generated content rather than creating from scratch.

---

**Card 2:**
### 90%+
**Documentation Completeness**

Built-in validation ensures all required elements are captured: process steps, exceptions, pain points, controls, and systems. No more "we forgot to ask about X."

---

**Card 3:**
### 80%+
**First-Pass Approval Rate**

Executive summaries auto-generated from detailed documentation achieve high approval rates without additional SME involvement.

---

### Speaker Notes

> **Core message:** We're not asking SMEs to do something new â€” we're asking them to do something they're already good at (validating, correcting) instead of something they struggle with (writing from scratch).
>
> **Anticipate the ChatGPT question:** Someone will ask "Why can't we just upload our DTPs to ChatGPT?" Be ready with: "ChatGPT will tell you what your documentation says. ProcessMiner tells you what actually happens, validated by the people who do it. When was your last DTP update? 2019? 2021? ChatGPT doesn't know it's wrong."
>
> **Key differentiation:** "The fundamental problem isn't document retrieval â€” it's knowledge extraction. Your DTPs are a starting point, not the answer. ProcessMiner uses them as input to structured elicitation, then SMEs validate what's still accurate and surface what's missing."
>
> **Anticipate the numbers question:** "Where do these numbers come from?" These are from pilot testing with banking processes. Your mileage may vary, but the directional improvement is consistent.
>
> **Transition:** "Let me show you the team that makes this possible."

---

## Slide 3: The 6-Agent Ecosystem â†’ Transition to Demo

### McKinsey Principle Applied
**Action Title:** States what capability exists and why it matters
**SCQA Position:** Answer continuation (how the solution works)
**Pyramid:** Title gives the "so what" â€” specialized beats generalist
**One Message:** Six agents > one generalist = better outcomes

### Formatting Guidance
- **Layout:** 55/45 split â€” agent pipeline left, demo preview right
- **Background:** White with subtle grid pattern
- **Pipeline diagram:** Vertical flow with agent cards (icon + name + one-line description)
- **Agent cards:** Rounded rectangles with colored left border matching agent theme
- **Demo preview panel:** Light blue (#ebf8ff) background with numbered list
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## Six specialised agents â€” each with distinct expertise â€” deliver end-to-end transformation capability that a single generalist AI cannot match

---

### LEFT SECTION: The Agent Pipeline

**Subheading:**
*Each agent has domain-specific knowledge, templates, and workflows â€” they collaborate, not compete*

**Agent Pipeline (vertical flow diagram):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“‹ PROCESS DOCUMENTATION ANALYST                          â”‚
â”‚  Extracts AS-IS process knowledge through structured       â”‚
â”‚  elicitation. Generates comprehensive documentation        â”‚
â”‚  with full cross-referencing (PS#, PP#, CP#, EX#, SYS#).  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ›¡ï¸ CONTROL ANALYST      â”‚  â”‚  ðŸŽ¯ CLIENT JOURNEY       â”‚
â”‚  Maps regulatory        â”‚  â”‚  ANALYST                 â”‚
â”‚  requirements (FCA,     â”‚  â”‚  Analyses process from   â”‚
â”‚  PRA, GDPR, Consumer    â”‚  â”‚  client perspective.     â”‚
â”‚  Duty). Assesses        â”‚  â”‚  Calculates Client       â”‚
â”‚  control effectiveness. â”‚  â”‚  Effort Score (CES).     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                            â”‚
             â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ’¡ INNOVATION ANALYST   â”‚  â”‚  ðŸ”„ TRANSFORMATION       â”‚
â”‚  Researches market      â”‚  â”‚  AGENT                   â”‚
â”‚  trends, competitor     â”‚  â”‚  Designs TO-BE target    â”‚
â”‚  approaches, and        â”‚  â”‚  state. Quantifies       â”‚
â”‚  fintech innovations.   â”‚  â”‚  benefits. Creates       â”‚
â”‚  MoSCoW prioritisation. â”‚  â”‚  implementation roadmap. â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                            â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ—ï¸ IT ARCHITECT                                           â”‚
â”‚  Translates business requirements into technical           â”‚
â”‚  specifications. Creates functional and non-functional     â”‚
â”‚  requirements with full traceability to business needs.    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### RIGHT SECTION: Demo Preview

**Section Header:**
#### Today's Demonstration

**Panel Background:** Light blue (#ebf8ff)

**Explanatory Text:**
In the next 25 minutes, you will see two core capabilities in action:

**Demo Item 1:**
### 1. Document Extraction via Elicitation

Watch how the Process Documentation Analyst conducts a structured interview to extract process knowledge. You'll see:
- How questions are designed to minimise SME typing burden
- How the AI generates documentation in real-time
- The multi-altitude outputs produced from a single session

**Demo Item 2:**
### 2. Interactive Exploration via Party Mode

Experience how multiple agents collaborate on complex questions. You'll see:
- Intelligent agent selection based on your question
- Natural dialogue between specialists with different perspectives
- How agents build on and respectfully challenge each other's inputs

**Transition Text (bold, centered):**
> **Let's see it in action â†’**

---

### Speaker Notes

> **Agent explanation approach:** Don't read all the descriptions â€” just name each agent and its primary job in one sentence. The detail is there for people reading later.
>
> **Key point:** "These aren't six instances of ChatGPT. Each agent has been trained with specific domain knowledge, templates, and workflows. The Control Analyst knows FCA DISP rules. The Client Journey Analyst knows CES calculation methodology."
>
> **Transition:** Move to demo environment. Have all windows pre-loaded and ready.

---

# PHASE 2: DEMO SUPPORT SLIDES (Slides 4-12)

---

## Slide 4: Demo Expectations â€” What You Will (and Won't) See

### McKinsey Principle Applied
**Action Title:** Sets clear expectations to prevent distraction from core message
**Pyramid:** Title states the key caveat â€” body explains what to focus on
**One Message:** Focus on the methodology, not the interface
**Purpose:** Prevent "but it doesn't look polished" objections from derailing the demo

### Formatting Guidance
- **Layout:** Three-column layout â€” "What This Is" | "What You'll See" | "What's Coming"
- **Visual:** Use icons to distinguish demonstration elements
- **Tone:** Honest, confident â€” acknowledge limitations without apologising
- **Style:** Clean, minimal â€” this is a framing slide, not a content-heavy slide
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## This demo shows methodology and output quality using a mocked process â€” focus on what's produced, not the current command-line interface

---

### THREE-COLUMN LAYOUT

---

**COLUMN 1: What This Demo Is**

#### ðŸŽ¯ Proof of Methodology

| Element | Explanation |
|---------|-------------|
| **Mocked process** | Client Complaints Management â€” selected because it's universally understood and has clear regulatory context |
| **Representative, not production** | The process details are illustrative; the methodology applies to your actual processes |
| **Principle demonstration** | We're showing *how* ProcessMiner works, not a finished product demo |

**Key Point:**
> The value is in the methodology and output quality â€” not in a specific process being "correct"

---

**COLUMN 2: What You'll See Today**

#### ðŸ‘ï¸ Demo Sequence

| Step | What You'll Observe |
|------|---------------------|
| **1. Loading existing documentation** | How ProcessMiner ingests DTPs/existing docs as a starting point (not source of truth) |
| **2. Structured elicitation** | How the 9-step workflow extracts and validates SME knowledge |
| **3. Output generation** | The multi-altitude documentation suite produced |
| **4. Party Mode exploration** | Multi-agent collaboration on a transformation question |

**Interface Note:**
> âš ï¸ **Current interface is Claude CLI (command-line)**
>
> You'll see text-based interaction, not a polished GUI. This is intentional â€” we're validating methodology before investing in interface design.

---

**COLUMN 3: What's Coming (Not Today)**

#### ðŸ”® Future State

| Not in Today's Demo | Planned For |
|--------------------|-------------|
| Graphical user interface | Post-methodology validation |
| Integration with your systems | Implementation phase |
| Your actual processes | Pilot engagement |
| Production deployment | Scale phase |

**Why CLI First:**
> "Build the engine before painting the car."
>
> We're proving the methodology produces valuable outputs before investing in interface polish. The command-line approach lets us iterate quickly on what matters: the quality of knowledge extraction and documentation.

---

### BOTTOM SECTION: What to Watch For

**Callout Box (blue border):**
> ðŸ’¡ **During the demo, focus on:**
>
> 1. **Question design** â€” How questions minimise SME effort while maximising information capture
> 2. **Output quality** â€” Whether the generated documentation is production-ready
> 3. **Traceability** â€” How every element links to validated SME input
> 4. **Multi-agent value** â€” Whether diverse perspectives surface insights you'd otherwise miss
>
> **Don't focus on:** Interface aesthetics, click paths, or visual design â€” those come later

---

### Speaker Notes

> **Why this slide matters:** Senior decision-makers may be distracted by "it doesn't look like a finished product." Get ahead of this objection by explicitly framing what they should evaluate.
>
> **Confidence, not apology:** Don't say "sorry it's just command-line." Say "we deliberately chose to validate methodology before interface investment â€” you'll see why the outputs justify that approach."
>
> **Transition:** "With those expectations set, let me show you the process we'll use for today's demonstration."

---

## Slide 5: Demo Context â€” What We're Documenting

### McKinsey Principle Applied
**Action Title:** States why this process was chosen and what makes it representative
**Pyramid:** Title explains the relevance â€” body provides the evidence
**One Message:** Complaints is ideal because it has all the typical challenges

### Formatting Guidance
- **Layout:** Full-width process flow at top (30%), context details below (70%)
- **Process flow:** Horizontal swim-lane style with stage boxes and timing
- **Context section:** Three-column layout (Regulatory, Volume, Pain Points)
- **Color coding:** Use traffic light colors for pain severity indicators
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## Client Complaints Management exemplifies the documentation challenge: high regulatory pressure, significant volume, and processes that diverge from documentation

---

### TOP SECTION: Process Overview

**Process Flow Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COMPLAINT  â”‚â”€â”€â”€â–ºâ”‚ ACKNOWLEDGE â”‚â”€â”€â”€â–ºâ”‚ INVESTIGATE â”‚â”€â”€â”€â–ºâ”‚  RESOLVE &  â”‚â”€â”€â”€â–ºâ”‚  FOLLOW-UP  â”‚
â”‚  RECEIVED   â”‚    â”‚             â”‚    â”‚             â”‚    â”‚  RESPOND    â”‚    â”‚             â”‚
â”‚             â”‚    â”‚  Target:    â”‚    â”‚  Target:    â”‚    â”‚  Target:    â”‚    â”‚  Target:    â”‚
â”‚  Channels:  â”‚    â”‚  24-48 hrs  â”‚    â”‚  5-10 days  â”‚    â”‚  Day 15-20  â”‚    â”‚  Day 30-180 â”‚
â”‚  Email,     â”‚    â”‚             â”‚    â”‚             â”‚    â”‚             â”‚    â”‚             â”‚
â”‚  Phone,     â”‚    â”‚  Actual:    â”‚    â”‚  Actual:    â”‚    â”‚  Actual:    â”‚    â”‚  Actual:    â”‚
â”‚  Web, Post  â”‚    â”‚  24-72 hrs  â”‚    â”‚  7-21 days  â”‚    â”‚  Day 20-45  â”‚    â”‚  Inconsistentâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### BOTTOM SECTION: Context Details

**Three Columns:**

**Column 1: Regulatory Context**
#### Regulatory Requirements

| Regulation | Requirement |
|------------|-------------|
| **FCA DISP** | 8-week final response deadline |
| **Consumer Duty** | Evidence of good customer outcomes |
| **GDPR** | Data subject access requests within complaints |
| **SMCR** | Senior manager accountability for complaints handling |

**Risk Statement:**
âš ï¸ FCA fines for complaints handling failures have exceeded Â£100M+ in recent years across UK banking sector.

---

**Column 2: Volume & Complexity**
#### Operational Scale

| Metric | Value |
|--------|-------|
| **Monthly volume** | ~5,000 complaints |
| **Complaint categories** | 12 primary types |
| **Average handling time** | 18 days |
| **Escalation rate** | 15% to senior handlers |
| **FOS referral rate** | 8% |

**Trend:**
ðŸ“ˆ Volume increased 23% year-over-year driven by Consumer Duty awareness.

---

**Column 3: Known Pain Points**
#### Current Challenges

ðŸ”´ **High Severity**
- Manual triage causes 24-48hr delays
- Inconsistent categorisation across handlers

ðŸŸ¡ **Medium Severity**
- No real-time visibility for customers
- Root cause analysis is reactive, not proactive

ðŸŸ¢ **Lower Severity**
- Multiple systems require manual data re-entry
- Reporting requires spreadsheet consolidation

---

### Speaker Notes

> **Why this process:** Client complaints is ideal for demonstration because (1) everyone understands it, (2) it has clear regulatory pressure, (3) it touches multiple departments, and (4) the pain points are universal.
>
> **Localise if needed:** If your organisation has specific complaints data, substitute it here. Real numbers are more compelling than generic ones.
>
> **Transition:** "Now let me show you how we extract this knowledge systematically."

---

## Slide 5: Demo Part A â€” Elicitation Overview

### McKinsey Principle Applied
**Action Title:** States what the workflow achieves and how
**Pyramid:** Title gives the outcome â€” body shows the mechanism
**One Message:** Nine steps ensure complete coverage without SME overload

### Formatting Guidance
- **Layout:** Workflow diagram top (40%), design principles bottom (60%)
- **Workflow:** Horizontal numbered steps with connecting arrows
- **Current step highlight:** Use gold (#d69e2e) fill for "active" step during demo
- **Principles section:** Four cards in 2x2 grid with icons
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## The 9-step workflow ensures complete documentation coverage while minimising SME burden through multiple-choice questions and AI-generated drafts

---

### TOP SECTION: The 9-Step Workflow

**Subheading:**
*Each step focuses on one aspect â€” preventing overload while ensuring nothing is missed (MECE)*

**Workflow Diagram:**

```
Step 1        Step 2         Step 3        Step 4         Step 5
â”Œâ”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ INIT â”‚â”€â”€â”€â”€â–ºâ”‚EXISTINGâ”‚â”€â”€â”€â”€â–ºâ”‚OVERVIEWâ”‚â”€â”€â”€â”€â–ºâ”‚ STEPS â”‚â”€â”€â”€â”€â–ºâ”‚EXCEPT-â”‚
â”‚      â”‚     â”‚ DOCS  â”‚      â”‚       â”‚      â”‚       â”‚      â”‚ IONS â”‚
â”‚Captureâ”‚    â”‚Check forâ”‚    â”‚Purpose,â”‚    â”‚Map theâ”‚     â”‚Documentâ”‚
â”‚contribâ”‚    â”‚prior   â”‚     â”‚trigger,â”‚    â”‚15-25  â”‚     â”‚exceptionâ”‚
â”‚-utor  â”‚    â”‚documen-â”‚     â”‚frequencyâ”‚   â”‚main   â”‚     â”‚paths & â”‚
â”‚detailsâ”‚    â”‚tation  â”‚     â”‚volume  â”‚    â”‚processâ”‚     â”‚varia-  â”‚
â”‚       â”‚    â”‚to buildâ”‚     â”‚        â”‚    â”‚steps  â”‚     â”‚tions   â”‚
â”‚       â”‚    â”‚upon    â”‚     â”‚        â”‚    â”‚       â”‚     â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”˜
    â”‚            â”‚             â”‚             â”‚             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚             â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ PAIN â”‚â”€â”€â”€â”€â–ºâ”‚CONTROLSâ”‚â”€â”€â”€â”€â–ºâ”‚SYSTEMSâ”‚â”€â”€â”€â”€â–ºâ”‚VALID- â”‚â”€â”€â”€â”€â–ºâ”‚OUTPUT â”‚
â”‚POINTSâ”‚     â”‚       â”‚      â”‚       â”‚      â”‚ ATION â”‚     â”‚       â”‚
â”‚Captureâ”‚    â”‚Documentâ”‚     â”‚Catalogâ”‚     â”‚Completeâ”‚    â”‚Generateâ”‚
â”‚operat-â”‚    â”‚compli- â”‚     â”‚tools &â”‚     â”‚-ness  â”‚     â”‚5+ docs â”‚
â”‚ional  â”‚    â”‚ance    â”‚     â”‚applic-â”‚     â”‚check & â”‚    â”‚from    â”‚
â”‚issues â”‚    â”‚controlsâ”‚     â”‚ations â”‚     â”‚SME    â”‚     â”‚capturedâ”‚
â”‚& root â”‚    â”‚& check-â”‚     â”‚involvedâ”‚    â”‚sign-offâ”‚    â”‚data    â”‚
â”‚causes â”‚    â”‚points  â”‚     â”‚        â”‚    â”‚        â”‚     â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”˜
Step 6        Step 7         Step 8        Step 9         Final
```

---

### BOTTOM SECTION: Design Principles

**Section Header:**
#### Why This Approach Works

**Four Principle Cards (2x2 grid):**

**Card 1:**
#### ðŸŽ¯ Multiple-Choice First
Questions are designed with pre-populated options wherever possible. SMEs select rather than type. This reduces effort by 60-70% compared to open-ended questioning while maintaining accuracy through "Other" escape hatches.

---

**Card 2:**
#### â¸ï¸ Session Flexibility
SMEs can pause at any point. Sessions auto-save every 5 minutes. A 30-minute session can be split across multiple days if needed. No work is ever lost.

---

**Card 3:**
#### âœï¸ AI Drafts, SME Validates
The system generates documentation drafts based on SME inputs. SMEs review and correct rather than write from scratch. This plays to human strengths (error detection) rather than weaknesses (blank-page creation).

---

**Card 4:**
#### ðŸ”— Structured Cross-Referencing
Every item receives a unique identifier (PS001, PP003, etc.). These IDs link across all documents, enabling full traceability from executive summary to technical specification to original SME input.

---

### Speaker Notes

> **Demo guidance:** During live demo, highlight Step 4 (Process Steps) to show the multiple-choice question design. Show Step 6 (Pain Points) to demonstrate how the system captures root causes alongside symptoms.
>
> **Key differentiation:** "This isn't a chatbot conversation. It's a structured interview designed by process documentation experts, delivered by AI."

---

## Slide 6: Structured Reference System

### McKinsey Principle Applied
**Action Title:** States the benefit of the ID system, not just that it exists
**Pyramid:** Title gives the "so what" (traceability) â€” body shows the mechanism
**One Message:** IDs enable audit trail from decision back to validated source

### Formatting Guidance
- **Layout:** Reference table left (45%), traceability diagram right (55%)
- **Reference table:** Clean table with colored prefix badges
- **Traceability diagram:** Flow diagram showing how IDs connect across documents
- **Color coding:** Each prefix type gets a consistent color throughout deck
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## Unique identifiers (PS#, PP#, CP#) enable full traceability â€” from IT specification back to validated SME input â€” critical for audit and regulatory defence

---

### LEFT SECTION: The ID System

**Subheading:**
*When the FCA asks "why did you make this decision?", you have a documented chain of evidence*

**Reference Table:**

| Prefix | Meaning | Color Code | Example |
|--------|---------|------------|---------|
| **PS#** | Process Step | ðŸ”µ Blue | PS001: Receive complaint via email/phone/web portal |
| **EX#** | Exception Path | ðŸŸ  Orange | EX001: Escalation to senior handler when value >Â£10k |
| **PP#** | Pain Point | ðŸ”´ Red | PP001: Manual triage causes 24-48hr initial delays |
| **CP#** | Control Point | ðŸŸ¢ Green | CP001: 24-hour acknowledgment SLA with auto-alert |
| **SYS#** | System | ðŸŸ£ Purple | SYS001: Salesforce CRM for complaint logging |
| **EI#** | Enhancement Idea | ðŸŸ¡ Gold | EI001: Implement AI-powered complaint categorisation |
| **INV#** | Innovation | âšª Teal | INV-001: Chatbot for first-line complaint handling |

---

### RIGHT SECTION: Traceability in Action

**Section Header:**
#### How IDs Connect Across Documents

**Traceability Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PAIN POINT: PP003                            â”‚
â”‚     "Manual complaint categorisation causes inconsistent        â”‚
â”‚      routing and delays of 24-48 hours"                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AFFECTS STEPS   â”‚  â”‚ TRIGGERS        â”‚  â”‚ ADDRESSED BY    â”‚
â”‚                 â”‚  â”‚ CONTROL         â”‚  â”‚                 â”‚
â”‚ â€¢ PS002: Log    â”‚  â”‚                 â”‚  â”‚ â€¢ EI003: AI     â”‚
â”‚   complaint     â”‚  â”‚ â€¢ CP002: Daily  â”‚  â”‚   categorisationâ”‚
â”‚ â€¢ PS003: Triage â”‚  â”‚   triage audit  â”‚  â”‚ â€¢ INV-007:      â”‚
â”‚   & categorise  â”‚  â”‚   by supervisor â”‚  â”‚   ML routing    â”‚
â”‚ â€¢ PS004: Route  â”‚  â”‚                 â”‚  â”‚   engine        â”‚
â”‚   to handler    â”‚  â”‚                 â”‚  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 TRANSFORMATION IMPACT                           â”‚
â”‚                                                                 â”‚
â”‚  TO-BE State: Automated ML categorisation (TO003)               â”‚
â”‚  Benefit: 90% reduction in triage time, 95%+ routing accuracy   â”‚
â”‚  Investment: Â£85k implementation, Â£15k annual maintenance       â”‚
â”‚  Traceability: TO003 â† INV-007 â† EI003 â† PP003 â† PS002-004     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Message (bold, centered):**
> **From pain point to solution to investment â€” fully traceable.**

---

### Speaker Notes

> **Why this matters:** "When the CFO asks 'why are we spending Â£85k on ML categorisation?', you have a complete answer: it addresses PP003, which affects steps PS002-004, was validated by [SME name], and will reduce triage time by 90%."
>
> **Audit value:** "For regulated industries, this traceability is invaluable. You can demonstrate exactly why each transformation decision was made and who validated the underlying business need."

---

## Slide 7: Demo Output Preview â€” Document Suite

### McKinsey Principle Applied
**Action Title:** Quantifies the output and states the key benefit
**Pyramid:** Title gives the "so what" â€” body shows what's produced
**One Message:** One session creates multiple documents for multiple audiences

### Formatting Guidance
- **Layout:** Document cards in a "fan" or "stack" arrangement
- **Each card:** Shows document name, purpose, primary audience, and sample content preview
- **Visual:** Slight rotation/offset to create depth effect
- **Size indicators:** Show approximate length of each document
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## One 30-minute session produces five documents at multiple altitudes â€” executive summary to technical specification â€” with zero additional SME time

---

### FULL SLIDE: The Document Suite

**Subheading:**
*Same validated data source, multiple audience-appropriate outputs*

**Document Cards:**

---

**Document 1 (Front of stack):**
### ðŸ“„ as-is-process-documentation.md
**Purpose:** Comprehensive process documentation with full detail
**Audience:** Process owners, business analysts, transformation teams
**Typical length:** 15-25 pages (~4,500-6,500 words)
**Contains:**
- Complete process step descriptions with entry/exit criteria
- Roles and responsibilities matrix
- Decision points and business rules
- System interactions and data flows
- Full cross-reference to all PP#, CP#, EX#, SYS# items

---

**Document 2:**
### ðŸ“‹ exec-summary-as-is.md
**Purpose:** Executive overview for steering committees and sponsors
**Audience:** Senior leadership, programme boards
**Typical length:** 2-3 pages (~800-1,200 words)
**Contains:**
- Process overview and business context
- Key metrics (volume, cycle time, cost indicators)
- Top 3-5 pain points with business impact
- High-level transformation opportunities
- Recommended next steps

---

**Document 3:**
### ðŸ”´ pain-points-detail.md
**Purpose:** Deep analysis of operational issues for transformation planning
**Audience:** Transformation leads, continuous improvement teams
**Typical length:** 8-12 pages (~3,000-4,500 words)
**Contains:**
- Each pain point with unique PP# identifier
- Root cause analysis (not just symptoms)
- Affected process steps (cross-referenced)
- Business impact quantification
- Initial solution hypotheses

---

**Document 4:**
### ðŸŸ¢ control-points-detail.md
**Purpose:** Compliance and control documentation for risk functions
**Audience:** Compliance officers, internal audit, risk managers
**Typical length:** 6-10 pages (~2,500-4,000 words)
**Contains:**
- Each control point with unique CP# identifier
- Regulatory requirement mapping
- Control effectiveness assessment (High/Medium/Low)
- Evidence requirements
- Gap analysis and remediation recommendations

---

**Document 5 (Back of stack):**
### ðŸ’¾ structured-data.json
**Purpose:** Machine-readable data for downstream processing
**Audience:** Other ProcessMiner agents, automation tools, analytics
**Typical length:** 50-100 KB
**Contains:**
- All captured data in structured JSON format
- Complete ID registry (PS#, PP#, CP#, EX#, SYS#)
- Relationship mappings between elements
- Metadata (contributor, timestamp, confidence levels)
- Ready for consumption by downstream agents

---

**Summary Statement (bold box at bottom):**
> **Total documentation from one 30-minute session: ~12,000-15,000 words across 5 documents**
>
> **Equivalent manual effort: 4-6 weeks of SME time**

---

### Speaker Notes

> **Show actual files:** After this slide, switch to file browser and show the actual generated documents from the P005 demo. Scroll through briefly to show volume and quality.
>
> **Key point:** "Notice these aren't drafts that need heavy editing. They're production-ready documents with consistent formatting, complete cross-referencing, and audit-ready metadata."

---

## Slide 8: Demo Part B â€” Party Mode Introduction

### McKinsey Principle Applied
**Action Title:** States the benefit of multi-agent collaboration, not just what it is
**Pyramid:** Title gives the outcome â€” body demonstrates with example
**One Message:** Multiple expert perspectives in one conversation beats separate meetings

### Formatting Guidance
- **Layout:** Conversation mockup taking most of slide (75%), explanation panel below (25%)
- **Conversation:** Chat-style interface with agent avatars and colored message bubbles
- **Agent colors:** Each agent gets consistent color (match pipeline diagram)
- **User message:** Distinct styling (right-aligned, different background)
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## Party Mode delivers four expert perspectives in one conversation â€” replacing weeks of separate stakeholder meetings with immediate multi-disciplinary synthesis

---

### MAIN SECTION: Multi-Agent Conversation Example

**User Query (right-aligned, gray background):**
> **USER:** "How should we approach redesigning our complaints resolution process? What are the key considerations?"

---

**Agent Response 1 (left-aligned, blue tint):**
ðŸŽ¯ **CLIENT JOURNEY ANALYST:**

"Complaints are loyalty moments â€” research shows customers who have complaints resolved well are often *more* loyal than those who never complained. The key metric isn't just resolution time, but perceived effort. Our current CES score of 65/100 indicates high customer effort, particularly during the investigation stage where customers report feeling 'in the dark' about progress.

**Priority considerations from a client perspective:**
- Real-time status visibility (biggest friction driver)
- Proactive communication (don't make them chase)
- Empowerment of first-line handlers to resolve without escalation"

---

**Agent Response 2 (left-aligned, green tint):**
ðŸ›¡ï¸ **CONTROL ANALYST:**

"Before we redesign, we must establish non-negotiable compliance boundaries. FCA DISP requires final response within 8 weeks, but the spirit of Consumer Duty goes further â€” we need to evidence that our process delivers good outcomes, not just technical compliance.

**Regulatory constraints that must be preserved:**
- 24-hour acknowledgment SLA (DISP 1.6.2)
- Written final response with FOS referral rights
- Complaint categorisation aligned to FCA reportable categories
- Root cause data for SYSC 10A.1 MI requirements

Any redesign must maintain these controls â€” they're not optional."

---

**Agent Response 3 (left-aligned, teal tint):**
ðŸ’¡ **INNOVATION ANALYST:**

"Looking at market trends, fintech competitors have fundamentally rethought complaints. Monzo resolves 70% of complaints in under 24 hours using in-app chat with empowered agents. Starling's AI triages and pre-populates case data, reducing handler admin by 40%.

**Innovations worth evaluating:**
- AI-powered categorisation and routing (proven, low risk)
- Chatbot for simple complaints (medium complexity)
- Predictive root cause identification (emerging, higher risk)

The gap between traditional banks and digital natives on complaints experience is widening. This is a competitive differentiator."

---

**Agent Response 4 (left-aligned, orange tint):**
ðŸ”„ **TRANSFORMATION AGENT:**

"Synthesising the inputs, I'd recommend a phased approach:

**Quick Wins (0-3 months):**
- Implement auto-acknowledgment with real-time status portal (addresses CES, maintains DISP compliance)
- Empower handlers with Â£500 discretionary resolution authority

**Core Transformation (3-9 months):**
- Deploy AI categorisation and intelligent routing
- Integrate complaint system with core banking for automated data pull

**Strategic Investment (9-18 months):**
- Build predictive model for proactive complaint prevention
- Develop customer self-service resolution for simple categories

Estimated investment: Â£350-500k. Estimated annual benefit: Â£1.2M (reduced handling time, lower FOS referrals, improved retention)."

---

### BOTTOM SECTION: Explanation

**Key Message (bold):**
> **Four perspectives. One conversation. Minutes, not meetings.**

**Explanatory Text:**
Party Mode intelligently selects relevant agents based on your question. Agents maintain distinct expertise and will respectfully challenge each other when they disagree. The conversation continues naturally, with agents building on each other's points.

---

### Speaker Notes

> **Live demo approach:** Ask a different question than shown here to demonstrate real-time agent selection. Good alternatives: "What technology should we prioritise?" or "How do we balance speed with compliance?"
>
> **Watch for:** Agent disagreements are valuable â€” they surface trade-offs that would otherwise require multiple meetings to identify.

---

## Slide 9: Party Mode â€” How It Works

### McKinsey Principle Applied
**Action Title:** States why the selection mechanism matters, not just how it works
**Pyramid:** Title gives the "so what" â€” body shows the mechanism
**One Message:** Intelligent selection ensures relevant experts respond, not random ones

### Formatting Guidance
- **Layout:** Technical flow diagram (60%), feature list (40%)
- **Flow diagram:** Vertical process flow with decision diamonds
- **Feature list:** Four features with icons and detailed descriptions
- **Style:** More technical than previous slides â€” this explains the "how"
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## Intelligent agent selection analyses your question and summons only relevant experts â€” ensuring you get domain-specific insight, not generic responses

---

### LEFT SECTION: Agent Selection Logic

**Subheading:**
*Different questions surface different agents â€” the system, not you, decides who should respond*

**Process Flow Diagram:**

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    USER QUESTION    â”‚
                    â”‚                     â”‚
                    â”‚  "How should we     â”‚
                    â”‚   redesign..."      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   QUESTION ANALYSIS â”‚
                    â”‚                     â”‚
                    â”‚ Extract:            â”‚
                    â”‚ â€¢ Domain keywords   â”‚
                    â”‚ â€¢ Intent type       â”‚
                    â”‚ â€¢ Complexity level  â”‚
                    â”‚ â€¢ Stakeholder scope â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  EXPERTISE MATCHING â”‚
                    â”‚                     â”‚
                    â”‚ Score each agent:   â”‚
                    â”‚ â€¢ Domain relevance  â”‚
                    â”‚ â€¢ Question fit      â”‚
                    â”‚ â€¢ Conversation gap  â”‚
                    â”‚ â€¢ Recency penalty   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   SELECT 2-4        â”‚
                    â”‚   TOP AGENTS        â”‚
                    â”‚                     â”‚
                    â”‚ Ensure diversity:   â”‚
                    â”‚ â€¢ Different domains â”‚
                    â”‚ â€¢ Complementary     â”‚
                    â”‚   perspectives      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    ORCHESTRATE      â”‚
                    â”‚    RESPONSES        â”‚
                    â”‚                     â”‚
                    â”‚ â€¢ Sequence for flow â”‚
                    â”‚ â€¢ Enable cross-talk â”‚
                    â”‚ â€¢ Manage turn-takingâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### RIGHT SECTION: Key Features

**Section Header:**
#### What Makes Party Mode Effective

**Feature 1:**
#### ðŸŽ­ Distinct Personalities
Each agent maintains a consistent persona, communication style, and area of expertise. The Control Analyst speaks differently than the Innovation Analyst â€” not just in content, but in tone, vocabulary, and level of caution. This mirrors real expert conversations.

---

**Feature 2:**
#### ðŸ”„ Natural Cross-Talk
Agents can reference each other by name, build on previous points, and respectfully disagree. "Building on what the Client Journey Analyst said..." or "I'd push back on that recommendation because..." This creates genuine synthesis, not parallel monologues.

---

**Feature 3:**
#### â“ Clarifying Questions
Agents can ask the user clarifying questions when needed. If your question is ambiguous or requires context they don't have, they'll ask rather than assume. This prevents hallucination and ensures relevance.

---

**Feature 4:**
#### ðŸ“Š Context Awareness
Agents have access to all previously generated documentation for the process. When discussing complaints, they reference actual pain points (PP003), actual controls (CP001), and actual metrics from your elicitation sessions. This isn't generic advice â€” it's grounded in your data.

---

### Speaker Notes

> **Technical depth:** This slide is for the "how does it work?" question. Most audiences won't need this detail â€” have it ready but don't linger unless asked.
>
> **Key differentiator:** "Unlike a single AI that tries to be everything, Party Mode brings genuine specialist perspectives. The Innovation Analyst has different training data than the Control Analyst. They actually know different things."

---

## Slide 10: Sample Outputs â€” What We Generated

### McKinsey Principle Applied
**Action Title:** States the quantified outcome with specific numbers
**Pyramid:** Title gives the key metrics â€” body provides breakdowns
**One Message:** Real results from real process â€” not projections
**Data-Driven:** Every claim backed by specific numbers from demo

### Formatting Guidance
- **Layout:** Metrics dashboard style with cards and charts
- **Cards:** Large numbers with supporting context
- **Visual:** Include mini-chart or icon for each metric
- **Color coding:** Use traffic lights for benchmark comparisons
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## The demo generated 200KB of documentation across 8 files â€” identifying 12 friction points, mapping 10 controls to 12 regulations, and specifying 18 prioritised innovations

---

### FULL SLIDE: Demonstration Results

**Subheading:**
*Actual outputs from Client Complaints Management (P005) â€” not projections*

---

**Metric Cards (2 rows of 3):**

**Row 1:**

**Card 1:**
### Client Effort Score
## 65/100
**Rating:** ðŸ”´ HIGH EFFORT

Industry benchmark: 55-60
Our process requires more customer effort than average, particularly during investigation stage where status visibility is poor.

---

**Card 2:**
### Friction Points Identified
## 12
**Across 5 journey stages**

| Severity | Count |
|----------|-------|
| ðŸ”´ High | 4 |
| ðŸŸ¡ Medium | 5 |
| ðŸŸ¢ Low | 3 |

Top friction: "No visibility of complaint status during investigation"

---

**Card 3:**
### Compliance Controls Mapped
## 10 controls â†’ 12 regulations

| Regulation | Controls |
|------------|----------|
| FCA DISP | 4 |
| Consumer Duty | 3 |
| GDPR | 2 |
| SMCR | 1 |

Control effectiveness: 5 High, 5 Medium, 0 Low

---

**Row 2:**

**Card 4:**
### Innovations Identified
## 18
**MoSCoW Prioritisation:**

| Priority | Count | Examples |
|----------|-------|----------|
| MUST | 7 | AI categorisation, status portal |
| SHOULD | 5 | Predictive analytics, self-service |
| COULD | 4 | Voice sentiment analysis |
| DEFER | 2 | Blockchain audit trail |

---

**Card 5:**
### Investment Estimate
## Â£450-600k
**Over 36 months**

| Phase | Investment |
|-------|------------|
| Quick wins (0-6mo) | Â£80-120k |
| Core transformation | Â£250-320k |
| Strategic initiatives | Â£120-160k |

ROI estimate: 18-24 month payback

---

**Card 6:**
### Documentation Generated
## ~200 KB
**Across 8 files**

| Document | Size |
|----------|------|
| AS-IS documentation | 18 KB |
| Pain points detail | 16 KB |
| Control assessment | 44 KB |
| CX analysis | 64 KB |
| Innovation analysis | 102 KB |

**Equivalent manual effort: 4-6 weeks**

---

### Speaker Notes

> **Reference actual files:** "These aren't mock numbers. Let me show you the actual Innovation Analysis document â€” 102KB, 1,750 lines, 18 fully specified innovations with feasibility scoring."
>
> **Investment context:** "The Â£450-600k estimate includes implementation costs, not operational savings. The ROI calculation shows payback within 18-24 months from reduced handling time and lower FOS referral rates."

---

## Slide 11: Transition to BMAD

### McKinsey Principle Applied
**Action Title:** States the strategic implication, not just what BMAD is
**Pyramid:** Title gives the "so what" â€” body shows the architecture
**One Message:** ProcessMiner is one application of a broader platform
**SCQA:** Sets up Phase 3 â€” there's more to explore

### Formatting Guidance
- **Layout:** Simple, clean transition slide
- **Visual:** "Built on" stack diagram â€” ProcessMiner sitting on BMAD foundation
- **Style:** Minimal text, strong visual hierarchy
- **Purpose:** Create curiosity for Phase 3
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## ProcessMiner is built on BMAD â€” a framework that can power similar transformation capability across any banking process, not just complaints

---

### FULL SLIDE: The Technology Behind ProcessMiner

**Visual Diagram:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚                       PROCESSMINER                              â”‚
â”‚                   Banking Process Module                        â”‚
â”‚                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚    â”‚ 6 Agents â”‚ â”‚18 Work-  â”‚ â”‚ Banking  â”‚ â”‚ Document â”‚        â”‚
â”‚    â”‚          â”‚ â”‚ flows    â”‚ â”‚Templates â”‚ â”‚ Suite    â”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚  Built on
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚                          BMAD                                   â”‚
â”‚            AI Agent Orchestration Framework                     â”‚
â”‚                                                                 â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚    â”‚ Agent    â”‚ â”‚ Workflow â”‚ â”‚ Module   â”‚ â”‚ State    â”‚        â”‚
â”‚    â”‚ Frameworkâ”‚ â”‚ Engine   â”‚ â”‚ System   â”‚ â”‚Managementâ”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                 â”‚
â”‚              19 Agents â”‚ 50+ Workflows â”‚ Extensible             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Transition Statement:**
> **ProcessMiner is one module built on a powerful foundation.**
>
> The same framework that powers complaints documentation can address any process across the bank.

**Teaser Questions:**
- What other banking processes have the same documentation challenges?
- Where else do you have SME knowledge trapped in people's heads?
- What other transformations need traceable, auditable foundations?

---

### Speaker Notes

> **Purpose of this slide:** Create the bridge to Phase 3. ProcessMiner isn't a one-trick pony â€” it's the first application of a broader capability.
>
> **Transition:** "Let me spend the final few minutes explaining what BMAD is and how it applies across banking."

---

# PHASE 3: BMAD & BANKING APPLICATIONS (Slides 12-14)

---

## Slide 12: What is BMAD?

### McKinsey Principle Applied
**Action Title:** States why BMAD matters for banking, not just what it is
**Pyramid:** Title gives the strategic value â€” body shows capabilities
**One Message:** BMAD solves the "why not just use ChatGPT" question
**MECE:** Comparison table covers all relevant dimensions without overlap

### Formatting Guidance
- **Layout:** 50/50 split â€” capabilities left, banking comparison right
- **Capabilities:** Stacked feature blocks with icons
- **Comparison table:** Two-column with clear visual distinction
- **Banking focus:** Emphasise regulated industry requirements
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## BMAD provides the audit trails, regulatory awareness, and structured workflows that generic AI lacks â€” making it suitable for regulated banking environments where ChatGPT alone fails

---

### LEFT SECTION: BMAD Capabilities

**Subheading:**
*A framework for building enterprise AI capabilities, not just a chatbot*

**Capability Blocks:**

**Block 1: Agent Framework**
#### ðŸ¤– 19 Specialized Agents (Extensible)
Pre-built agents for common roles (architect, analyst, developer, etc.) plus the ability to create custom agents with specific expertise, personality, and workflows. Each agent maintains distinct knowledge and capabilities.

---

**Block 2: Workflow Engine**
#### âš™ï¸ 50+ Guided Workflows
Structured, step-based workflows that guide agents through complex processes. Workflows ensure consistency, capture state, and enable pause/resume. New workflows can be created for any process.

---

**Block 3: Audit & Compliance**
#### ðŸ“‹ Built-in Audit Trails
Every agent action, every document generated, every decision made is logged with full traceability. Essential for regulated industries where "how did we get here?" questions must be answerable.

---

**Block 4: Scale Adaptive**
#### ðŸ“ˆ Small to Enterprise
The same framework handles a simple bug fix and an enterprise transformation programme. Complexity is managed, not multiplied.

---

### RIGHT SECTION: Why BMAD for Banking?

**Section Header:**
#### The "Just Use ChatGPT" Question â€” Answered

**Explanatory Text:**
We anticipate this question: "We have DTPs. Why not just upload them to ChatGPT and ask questions?" Here's the comprehensive answer:

**Comparison Table:**

| Aspect | "Upload DTP to ChatGPT" | BMAD / ProcessMiner |
|--------|------------------------|---------------------|
| **Knowledge source** | Static documents (often outdated) | Live SME validation of current reality |
| **Actual vs. documented process** | Only knows what's written | Elicits tribal knowledge and workarounds |
| **Gap identification** | Assumes documents are complete | Structured questions surface missing elements |
| **Pain point capture** | âŒ DTPs don't contain pain points | âœ… Dedicated elicitation step for pain points |
| **Compliance awareness** | Generic â€” no banking regulatory knowledge | FCA, PRA, GDPR, Consumer Duty built-in |
| **Output structure** | Unstructured chat responses | Templated, multi-altitude documentation |
| **Traceability** | Conversations disappear | Full audit trail with unique IDs (PS#, PP#, etc.) |
| **SME validation** | None â€” AI just repeats documents | Built into every workflow step |
| **Multi-perspective analysis** | Single generalist voice | 6 specialized agents with different expertise |
| **Transformation readiness** | Answers questions about AS-IS | Generates AS-IS, analyses gaps, designs TO-BE |

**Callout Box (blue border):**
> ðŸ’¡ **The Core Difference**
>
> **ChatGPT + DTPs** answers: "What does your documentation say?"
>
> **ProcessMiner** answers: "What actually happens, what's broken, and how should it change?"
>
> For transformation, you need the second answer. Documents are inputs, not outputs.

**Key Message:**
> **Generic AI is a powerful retrieval tool. BMAD is a framework for knowledge extraction, validation, and transformation in regulated environments.**

---

### Speaker Notes

> **The ChatGPT objection will come:** Be ready. The answer is: "ChatGPT tells you what your documents say. ProcessMiner tells you what actually happens. For transformation, you need reality, not documentation."
>
> **Concrete example:** "Your DTP says 'categorise complaint using standard taxonomy.' It doesn't say the dropdown has 200 options, no search function, and takes handlers 15 minutes because they have to scroll through looking for the right category. That pain point lives in your SME's head, not in any document."
>
> **Audit angle for compliance-focused audience:** "When the FCA asks 'how did you determine this control was adequate?', 'ChatGPT said so based on a 2019 DTP' is not a defensible answer. 'SME validated on [date], cross-referenced to PS004 and CP002, logged in session transcript' is."
>
> **Positioning:** BMAD isn't competing with ChatGPT â€” it uses the same underlying AI technology but adds the structure, validation, and governance that regulated industries require. ChatGPT is a component, not a solution.

---

## Slide 13: Banking Applications Beyond Complaints

### McKinsey Principle Applied
**Action Title:** States the scaling opportunity with specific domains
**Pyramid:** Title gives the strategic implication â€” body provides MECE breakdown
**One Message:** The same methodology scales across the entire bank
**MECE:** Six domains cover banking operations comprehensively without overlap

### Formatting Guidance
- **Layout:** Six domain cards in 2x3 grid
- **Each card:** Domain name, icon, 3-4 specific use cases
- **Visual:** Banking-specific iconography
- **Bottom section:** Architecture showing module approach
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## The same methodology scales across six major banking domains â€” Onboarding, Lending, Payments, Operations, Risk, and Regulatory Reporting â€” each facing identical documentation and transformation challenges

---

### MAIN SECTION: Banking Process Applications

**Subheading:**
*Every domain has SMEs with tribal knowledge, scattered documentation, and transformation needs â€” ProcessMiner addresses all*

**Domain Cards (2 rows of 3):**

---

**Card 1:**
### ðŸ¦ CLIENT ONBOARDING

**Use Cases:**
- **KYC/AML workflow documentation** â€” Capture the actual process, not the policy document
- **Document collection optimisation** â€” Identify friction points in client evidence gathering
- **Due diligence process transformation** â€” Design target state with compliance preserved
- **Onboarding journey mapping** â€” CES scoring for prospective clients

**Regulatory relevance:** MLR 2017, FCA Financial Crime Guide, Consumer Duty

---

**Card 2:**
### ðŸ’³ LENDING & CREDIT

**Use Cases:**
- **Credit decisioning process documentation** â€” Map manual overrides and exceptions
- **Loan origination transformation** â€” Identify automation opportunities
- **Collections process redesign** â€” Balance efficiency with vulnerable customer handling
- **Affordability assessment workflows** â€” Ensure Consumer Duty compliance

**Regulatory relevance:** MCOB, Consumer Duty, FCA Affordability Rules

---

**Card 3:**
### ðŸ’¸ PAYMENTS & TRANSACTIONS

**Use Cases:**
- **Payment processing workflow mapping** â€” Document real vs. documented process
- **Fraud detection process analysis** â€” Identify control gaps and false positive drivers
- **Faster Payments transformation** â€” Design for new payment rails
- **Cross-border payment optimisation** â€” Map pain points in correspondent banking

**Regulatory relevance:** PSR 2017, APP Fraud Requirements, PSD2

---

**Card 4:**
### âš™ï¸ BANKING OPERATIONS

**Use Cases:**
- **Account servicing process documentation** â€” Capture tribal knowledge before it leaves
- **Trade settlement workflow mapping** â€” Identify T+1 readiness gaps
- **Reconciliation process transformation** â€” Design automated exception handling
- **Branch operations standardisation** â€” Document variation across locations

**Regulatory relevance:** CASS, Operational Resilience, MiFID II

---

**Card 5:**
### ðŸ“Š RISK MANAGEMENT

**Use Cases:**
- **Credit risk process documentation** â€” Map model inputs and manual adjustments
- **Operational risk event handling** â€” Capture RCSA process reality
- **Model validation workflows** â€” Document challenger model processes
- **Stress testing process mapping** â€” Identify data lineage and manual interventions

**Regulatory relevance:** Basel III/IV, SS1/23, PRA Rulebook

---

**Card 6:**
### ðŸ“‹ REGULATORY REPORTING

**Use Cases:**
- **Regulatory return production** â€” Document the actual process, identify risks
- **ICAAP/ILAAP preparation** â€” Capture narrative development process
- **Pillar 3 disclosure workflow** â€” Map data sourcing and sign-off chains
- **Consumer Duty evidence gathering** â€” Document how outcomes are evidenced

**Regulatory relevance:** All prudential and conduct regulation

---

### BOTTOM SECTION: Modular Architecture

**Architecture Diagram:**

```
                         BMAD CORE (Framework)
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚           â”‚           â”‚
        â–¼           â–¼           â–¼           â–¼           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Complaintsâ”‚ â”‚Onboardingâ”‚ â”‚ Lending â”‚ â”‚Payments â”‚ â”‚  Risk   â”‚
   â”‚ Module  â”‚ â”‚  Module  â”‚ â”‚ Module  â”‚ â”‚ Module  â”‚ â”‚ Module  â”‚
   â”‚         â”‚ â”‚          â”‚ â”‚         â”‚ â”‚         â”‚ â”‚         â”‚
   â”‚(Today's â”‚ â”‚(Same     â”‚ â”‚(Same    â”‚ â”‚(Same    â”‚ â”‚(Same    â”‚
   â”‚ demo)   â”‚ â”‚method)   â”‚ â”‚method)  â”‚ â”‚method)  â”‚ â”‚method)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Speaker Notes

> **Don't read all cards:** Pick 1-2 that resonate with your audience's priorities. "I see several of you from the retail bank â€” the onboarding use case might be particularly relevant."
>
> **Key message:** "We're not asking you to buy a complaints tool. We're showing you a methodology that scales across banking. Complaints is the proof point."

---

## Slide 14: Summary + Next Steps

### McKinsey Principle Applied
**Action Title:** States the call to action with specific next step
**Pyramid:** Title gives the recommendation â€” body supports with details
**Rule of Three:** Exactly three takeaways (McKinsey standard)
**One Message:** Clear call to action â€” pilot with 2-3 processes

### Formatting Guidance
- **Layout:** Left (55%) = three takeaways, Right (45%) = pilot path and next steps
- **Takeaways:** Large numbered blocks with brief explanation
- **Pilot path:** Horizontal timeline with phases
- **Contact section:** Clear call to action
- **Action title:** Full sentence at top, bold 24pt

---

### ACTION TITLE (Top of slide, bold, 24pt)
## Three takeaways and one recommendation: pilot ProcessMiner on 2-3 banking processes to validate the 70%+ SME time reduction in your environment

---

### LEFT SECTION: Three Takeaways (Rule of Three)

**Subheading:**
*If you remember nothing else, remember these*

**Takeaway 1:**
## 1
### FLIP THE BURDEN

**Traditional approach:** Ask SMEs to write documentation from scratch â€” a task they dislike and deprioritise.

**ProcessMiner approach:** AI drafts comprehensive documentation based on structured questions; SMEs validate and correct.

**Result:** 70%+ reduction in SME time. 30-minute sessions produce documentation that would take weeks.

---

**Takeaway 2:**
## 2
### ORCHESTRATED EXPERTISE

**Traditional approach:** One general-purpose AI tries to be an expert in everything â€” and hallucinates when it isn't.

**ProcessMiner approach:** Six specialized agents with distinct expertise, working together through structured handoffs.

**Result:** Control Analyst knows FCA DISP. Innovation Analyst knows fintech trends. They bring different, complementary perspectives.

---

**Takeaway 3:**
## 3
### BUILT FOR REGULATED INDUSTRIES

**Traditional approach:** AI conversations disappear. No audit trail. No traceability. "Why did we decide this?" has no answer.

**ProcessMiner approach:** Every input, every output, every decision is logged with unique identifiers and full traceability.

**Result:** When the regulator asks "how did you reach this transformation decision?", you have a complete, auditable answer.

---

### RIGHT SECTION: Next Steps

**Section Header:**
#### Suggested Pilot Approach

**Pilot Timeline:**

```
     PILOT                    SCALE                     EXPAND
   (4-6 weeks)              (3-6 months)             (6-12 months)
       â”‚                         â”‚                         â”‚
       â–¼                         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2-3 Banking â”‚           â”‚ Division-   â”‚           â”‚ Enterprise  â”‚
â”‚ Processes   â”‚    â”€â”€â–º    â”‚ Wide        â”‚    â”€â”€â–º    â”‚ Roll-out    â”‚
â”‚             â”‚           â”‚ Deployment  â”‚           â”‚             â”‚
â”‚ â€¢ Complaintsâ”‚           â”‚ â€¢ Onboardingâ”‚           â”‚ â€¢ Lending   â”‚
â”‚   (done)    â”‚           â”‚ â€¢ Payments  â”‚           â”‚ â€¢ Risk      â”‚
â”‚ â€¢ KYC/AML   â”‚           â”‚ â€¢ Operationsâ”‚           â”‚ â€¢ Regulatoryâ”‚
â”‚ â€¢ Account   â”‚           â”‚             â”‚           â”‚   Reporting â”‚
â”‚   servicing â”‚           â”‚             â”‚           â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ideal Pilot Process Criteria:**
- âœ… Known pain points and transformation appetite
- âœ… SME available for 2-3 sessions (30 minutes each)
- âœ… Regulatory pressure creating urgency
- âœ… Clear success metrics definable

**Immediate Next Steps:**
1. Identify 2-3 pilot candidate processes
2. Schedule 30-minute scoping session
3. Run first elicitation within 2 weeks
4. Review outputs and decide on scale

---

**Call to Action:**
### Questions & Discussion

**Contact:**
[Your name]
[Your email]
[Your phone]

**Offer:**
> "Happy to schedule a working session to identify the best pilot candidates for your organisation."

---

### Speaker Notes

> **Land the three points:** These are the "tell your boss" summary. If attendees remember nothing else, remember these three.
>
> **Pilot offer:** Be specific about next steps. Vague "let's follow up" loses momentum. Propose a specific scoping session.
>
> **Time check:** You should have 3-5 minutes for Q&A. If running short, skip the pilot timeline detail and go straight to "Questions?"

---

# BACKUP SLIDES

---

## Backup Slide B1: Elicitation Screenshots

**Purpose:** If live demo fails, walk through static screenshots

**Include:**
- Screenshot of session initialization (contributor capture)
- Screenshot of multiple-choice question with options
- Screenshot of pain point capture with root cause fields
- Screenshot of generated documentation preview
- Screenshot of session save/resume functionality

---

## Backup Slide B2: Party Mode Transcript

**Purpose:** Full example conversation if live demo fails

**Include:** Complete transcript of Party Mode conversation on a different topic than shown in main deck (e.g., "How do we improve first-call resolution?")

---

## Backup Slide B3: Output Document Samples

**Purpose:** Show actual document quality

**Include:**
- Executive summary sample (2-page excerpt)
- Detailed process documentation sample (showing PS# formatting)
- Structured JSON sample (showing data model)

---

## Backup Slide B4: Technical Architecture

**Purpose:** For technical audience questions

**Include:**
- Workflow execution model diagram
- Data flow between agents
- File storage and versioning structure
- Integration points

---

## Backup Slide B5: Compliance Framework Mapping

**Purpose:** For compliance-focused questions

**Include:** Matrix showing all regulations mapped:
- FCA DISP (complaints handling)
- Consumer Duty (outcomes monitoring)
- GDPR (data subject rights)
- SMCR (accountability)
- MLR 2017 (AML requirements)
- Basel III/IV (risk frameworks)

---

## Backup Slide B6: Comparison with Alternatives

**Purpose:** For competitive questions

**Include comparison matrix:**

| Capability | ProcessMiner | Signavio/ARIS | Generic AI | Consulting |
|------------|--------------|---------------|------------|------------|
| SME time required | Low | High | Medium | Very High |
| Documentation quality | High (validated) | Varies | Inconsistent | High |
| Audit trail | Built-in | Partial | None | Manual |
| Multi-altitude output | Automatic | Manual | Manual | Manual |
| Compliance awareness | Banking-specific | Generic | None | Varies |
| Time to value | Days | Weeks | Hours | Months |
| Cost | Software | Software + Training | Low | Very High |

---

## Backup Slide B7: Deep Dive â€” "Why Not Just Upload DTPs to ChatGPT?"

**Purpose:** Detailed response to the most common objection

### Formatting Guidance
- **Layout:** Problem statement top, detailed comparison middle, summary bottom
- **Visual:** Side-by-side workflow diagrams
- **Tone:** Respectful but clear â€” acknowledge the intuition, explain the limitation

---

### THE INTUITION (Why People Ask This)

**The Question:**
> "We have Desktop Procedures and process documentation. Can't we just upload them to ChatGPT and ask questions about our processes?"

**Why It Seems Reasonable:**
- ChatGPT is powerful and accessible
- DTPs exist and represent significant past investment
- Uploading documents is easy
- Initial answers seem plausible

**The Short Answer:**
> ChatGPT will tell you what your documents say. ProcessMiner will tell you what actually happens. For transformation, you need reality.

---

### THE PROBLEM IN DETAIL

**Issue 1: Documents Describe Design, Not Reality**

| What the DTP Says | What Actually Happens |
|-------------------|----------------------|
| "Categorise complaint using standard taxonomy" | Handlers scroll through 200 options for 15 minutes because there's no search |
| "Escalate to senior handler if complex" | "Complex" isn't defined â€” handlers use gut feel, inconsistently |
| "Response within 48 hours" | Template says 48 hours but system sends at 72 hours due to batch processing |
| "Log in CRM system" | Handlers also log in Excel because CRM reporting is broken |

**ChatGPT cannot know these things.** It only knows what's written.

---

**Issue 2: DTPs Don't Contain Pain Points**

Process documentation describes *what to do*, not *what's broken*. Pain points like:
- "This step takes too long because..."
- "We always have to work around..."
- "The system doesn't let us..."
- "Customers complain that..."

...are not in any DTP. They live in SME heads. ProcessMiner's elicitation workflow specifically extracts these.

---

**Issue 3: No Validation Loop**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHATGPT + DTP APPROACH                       â”‚
â”‚                                                                 â”‚
â”‚   DTP (2019) â”€â”€â–º Upload â”€â”€â–º ChatGPT â”€â”€â–º Answer                 â”‚
â”‚                                                                 â”‚
â”‚   âŒ No check: Is DTP current?                                  â”‚
â”‚   âŒ No check: Does answer reflect reality?                     â”‚
â”‚   âŒ No SME validation                                          â”‚
â”‚   âŒ No confidence indicator                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCESSMINER APPROACH                        â”‚
â”‚                                                                 â”‚
â”‚   Existing Docs â”€â”€â–º Starting Point â”€â”€â–º Structured Elicitation  â”‚
â”‚                                              â”‚                  â”‚
â”‚                                              â–¼                  â”‚
â”‚                     SME Validation â—„â”€â”€ AI-Generated Draft       â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚                    Validated Documentation                      â”‚
â”‚                    (with confidence levels)                     â”‚
â”‚                                                                 â”‚
â”‚   âœ… SME confirms/corrects each element                        â”‚
â”‚   âœ… Gaps identified through structured questions              â”‚
â”‚   âœ… Pain points explicitly captured                           â”‚
â”‚   âœ… Full audit trail                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Issue 4: No Audit Trail for Regulated Industries**

| Scenario | ChatGPT Response | ProcessMiner Response |
|----------|-----------------|----------------------|
| "How do we know this control is effective?" | "The document says..." | "CP004 validated by [SME] on [date], effectiveness rated HIGH based on [criteria]" |
| "Why did we decide to change this step?" | No record | "TO003 addresses PP002 and PP005, validated in session 3, approved by [name]" |
| "Who confirmed this process description?" | Unknown | "Session transcript, contributor: Jane Smith (Operations Manager), 2024-03-15" |

---

**Issue 5: No Transformation Capability**

ChatGPT + DTPs can answer: "What does our process documentation say?"

It cannot:
- Identify pain points and root causes
- Map regulatory requirements to controls
- Analyse client experience and effort
- Research market innovations
- Design target-state processes
- Create IT specifications with traceability

ProcessMiner does all of these through its 6-agent ecosystem.

---

### WHEN CHATGPT + DTPS *IS* APPROPRIATE

To be fair, there are valid use cases:

| Use Case | ChatGPT + DTP | ProcessMiner |
|----------|---------------|--------------|
| Quick answer about documented procedure | âœ… Good enough | Overkill |
| Training new staff on basics | âœ… Useful | Overkill |
| Finding a specific policy reference | âœ… Fast | Overkill |
| **Process transformation** | âŒ Insufficient | âœ… Designed for this |
| **Compliance documentation** | âŒ No audit trail | âœ… Built-in |
| **Pain point analysis** | âŒ Not in documents | âœ… Explicit elicitation |
| **Multi-stakeholder alignment** | âŒ Single voice | âœ… 6 specialist agents |

---

### SUMMARY

**One-liner for Q&A:**
> "ChatGPT + DTPs is document retrieval. ProcessMiner is knowledge extraction and transformation. For understanding what your documents say, ChatGPT is fine. For understanding what actually happens and how to change it, you need ProcessMiner."

**The Killer Question to Ask Back:**
> "When was your complaints DTP last updated? 2019? 2021? How confident are you that it describes what actually happens today?"

---

# GHOST DECK: THE STORYLINE TEST

Read the action titles in sequence â€” they should tell a complete, logical story without any body content:

---

## Phase 1: The Problem & Solution

**Slide 1:** "Process documentation takes 4-6 weeks because SMEs must write from scratch â€” and uploading DTPs to ChatGPT doesn't fix this"

**Slide 2:** "Flipping the model â€” AI drafts, SMEs validate â€” reduces effort by 70%+ while improving documentation quality to 90%+"

**Slide 3:** "Six specialised agents â€” each with distinct expertise â€” deliver end-to-end transformation capability that a single generalist AI cannot match"

---

## Phase 2: The Demo (supporting live demonstration)

**Slide 4:** "This demo shows methodology and output quality using a mocked process â€” focus on what's produced, not the current command-line interface"

**Slide 5:** "Client Complaints Management exemplifies the documentation challenge: high regulatory pressure, significant volume, and processes that diverge from documentation"

**Slide 6:** "The 9-step workflow ensures complete documentation coverage while minimising SME burden through multiple-choice questions and AI-generated drafts"

**Slide 7:** "Unique identifiers (PS#, PP#, CP#) enable full traceability â€” from IT specification back to validated SME input â€” critical for audit and regulatory defence"

**Slide 8:** "One 30-minute session produces five documents at multiple altitudes â€” executive summary to technical specification â€” with zero additional SME time"

**Slide 9:** "Party Mode delivers four expert perspectives in one conversation â€” replacing weeks of separate stakeholder meetings with immediate multi-disciplinary synthesis"

**Slide 10:** "Intelligent agent selection analyses your question and summons only relevant experts â€” ensuring you get domain-specific insight, not generic responses"

**Slide 11:** "The demo generated 200KB of documentation across 8 files â€” identifying 12 friction points, mapping 10 controls to 12 regulations, and specifying 18 prioritised innovations"

**Slide 12:** "ProcessMiner is built on BMAD â€” a framework that can power similar transformation capability across any banking process, not just complaints"

---

## Phase 3: The Broader Opportunity

**Slide 13:** "BMAD provides the audit trails, regulatory awareness, and structured workflows that generic AI lacks â€” making it suitable for regulated banking environments where ChatGPT alone fails"

**Slide 14:** "The same methodology scales across six major banking domains â€” Onboarding, Lending, Payments, Operations, Risk, and Regulatory Reporting â€” each facing identical documentation and transformation challenges"

**Slide 15:** "Three takeaways and one recommendation: pilot ProcessMiner on 2-3 banking processes to validate the 70%+ SME time reduction in your environment"

---

## Storyline Validation âœ…

The ghost deck tells this story:

1. **Problem:** Documentation takes too long, ChatGPT doesn't help
2. **Solution:** Flip the model â€” AI drafts, humans validate
3. **How:** Six specialized agents working together
4. **Expectation setting:** Focus on methodology, not interface
5. **Proof:** Demo shows specific results with real process
6. **Platform:** Built on BMAD, which scales beyond this use case
7. **Call to Action:** Pilot on 2-3 processes

This follows the **Situation â†’ Complication â†’ Resolution** structure with clear **Pyramid Principle** (answer-first) communication.

---

# FORMATTING SUMMARY

## Colour Palette
| Use | Colour | Hex |
|-----|--------|-----|
| Primary (headers, key elements) | Deep Blue | #1a365d |
| Secondary (accents, highlights) | Teal | #319795 |
| Success/Positive | Green | #38a169 |
| Warning/Attention | Gold | #d69e2e |
| Error/Pain Points | Red | #e53e3e |
| Background | White/Light Gray | #ffffff / #f7fafc |
| Body Text | Dark Gray | #2d3748 |

## Typography
| Element | Font | Size | Weight |
|---------|------|------|--------|
| Slide Title | Sans-serif (Inter/Helvetica) | 36-48pt | Bold |
| Section Header | Sans-serif | 24-28pt | Bold |
| Body Text | Sans-serif | 16-18pt | Regular |
| Captions/Notes | Sans-serif | 12-14pt | Regular |
| Code/Technical | Monospace (JetBrains/Consolas) | 14pt | Regular |

## Layout Principles
- Maximum 6 lines of text per content block
- Minimum 30% white space on every slide
- Diagrams preferred over bullet points
- One key message per slide
- Visual hierarchy through size and colour

## Animation Guidelines
- Use sparingly (senior audience)
- Fade-in only (no fly/zoom/spin)
- Reveal complex diagrams in stages
- No animation on backup slides
