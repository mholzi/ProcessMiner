# Innovation Validation Rules
# ProcessMiner Module - IA Agent
# Version: 1.0.0
# Reference: example-registry.yaml, innovation-schema.yaml

validation_type: innovation-idea
agent: ia
description: "Validation rules for innovation ideas (II#) - ensures quality and completeness"

# =============================================================================
# Feasibility Score Requirements
# =============================================================================
feasibility_rules:
  - rule_id: FEAS-001
    name: "Complete 6-Dimension Assessment"
    severity: error
    description: "All innovation ideas must have complete feasibility assessment"
    check: |
      For each II#:
      - feasibility.technical is defined and between 1-5
      - feasibility.regulatory is defined and between 1-5
      - feasibility.financial is defined and between 1-5
      - feasibility.complexity is defined and between 1-5
      - feasibility.adoption is defined and between 1-5
      - feasibility.competitive is defined and between 1-5
    remediation: "Complete all 6 feasibility dimensions for each innovation idea"
    examples:
      good: "II#001 has all 6 dimensions scored"
      bad: "II#997 missing complexity, adoption, competitive scores"

  - rule_id: FEAS-002
    name: "Weighted Score Calculated"
    severity: error
    description: "Feasibility weighted_score must be calculated"
    check: |
      For each II#:
      - feasibility.weighted_score is defined
      - weighted_score = (technical + regulatory + financial + complexity + adoption + competitive) / 6
      - weighted_score is between 1.0 and 5.0
    remediation: "Calculate weighted_score as average of all 6 dimensions"
    examples:
      good: "II#001: (4+4+3+3+4+5)/6 = 3.8"
      bad: "II#997: weighted_score missing"

  - rule_id: FEAS-003
    name: "Score Range Validation"
    severity: error
    description: "All feasibility dimension scores must be 1-5"
    check: |
      For each II# and each dimension:
      - score >= 1
      - score <= 5
      - score is integer or half-integer (1, 1.5, 2, 2.5, etc.)
    remediation: "Use 1-5 scale for all feasibility dimensions"
    examples:
      good: "technical: 4, regulatory: 3.5"
      bad: "technical: 7, regulatory: 0"

  - rule_id: FEAS-004
    name: "Realistic Scoring"
    severity: warning
    description: "Avoid all-5 or all-1 scoring patterns"
    check: |
      For each II#:
      - Not all 6 dimensions are 5 (unrealistic perfection)
      - Not all 6 dimensions are 1 (complete infeasibility)
      - Standard deviation of scores > 0.5 (some variance expected)
    remediation: "Provide differentiated scoring across dimensions"
    examples:
      good: "II#001: scores range from 3 to 5"
      bad: "All dimensions scored 5 (unrealistic)"

# =============================================================================
# Priority-Feasibility Alignment
# =============================================================================
priority_rules:
  - rule_id: PRIO-001
    name: "Priority Assignment Required"
    severity: error
    description: "All innovation ideas must have MoSCoW priority"
    check: |
      For each II#:
      - priority is one of: must, should, could, defer
    remediation: "Assign MoSCoW priority to each innovation idea"
    examples:
      good: "priority: must"
      bad: "priority: high (use MoSCoW: must/should/could/defer)"

  - rule_id: PRIO-002
    name: "Must Priority Feasibility"
    severity: warning
    description: "Must-priority ideas should have high feasibility"
    check: |
      For each II# with priority=must:
      - weighted_score >= 3.5
    remediation: "Review priority for low-feasibility ideas marked as 'must'"
    examples:
      good: "II#001: priority=must, weighted_score=3.8"
      bad: "II#998: priority=must, weighted_score=1.7 (should be defer)"

  - rule_id: PRIO-003
    name: "Defer Priority Low Feasibility"
    severity: warning
    description: "Ideas with very low feasibility should be deferred"
    check: |
      For each II# with weighted_score < 2.5:
      - priority should be defer
    remediation: "Defer low-feasibility ideas until conditions improve"
    examples:
      good: "II#005: weighted_score=2.8, priority=defer"
      bad: "II#998: weighted_score=1.7, priority=must"

  - rule_id: PRIO-004
    name: "Balanced Priority Distribution"
    severity: info
    description: "Avoid marking everything as 'must' priority"
    check: |
      - Count(priority=must) should be < 40% of total ideas
      - At least 2 different priority levels used
    remediation: "Prioritize ruthlessly - not everything can be 'must'"
    examples:
      good: "2 must, 3 should, 2 could, 1 defer"
      bad: "8 must, 0 should, 0 could, 0 defer"

# =============================================================================
# ROI Requirements
# =============================================================================
roi_rules:
  - rule_id: ROI-001
    name: "High Priority ROI Required"
    severity: warning
    description: "Must/Should priority ideas should have ROI estimate"
    check: |
      For each II# with priority=must OR priority=should:
      - roi_estimate is defined
      - roi_estimate.investment_required is not empty
      - roi_estimate.annual_benefit is not empty
    remediation: "Provide ROI estimate for high-priority innovation ideas"
    examples:
      good: "II#001: priority=must, roi_estimate defined"
      bad: "II#999: priority=must, no roi_estimate"

  - rule_id: ROI-002
    name: "ROI Confidence Level"
    severity: info
    description: "ROI estimates should include confidence level"
    check: |
      For each II# with roi_estimate defined:
      - roi_estimate.confidence is one of: high, medium, low
    remediation: "Indicate confidence level in ROI estimates"
    examples:
      good: "confidence: medium (reflects uncertainty)"
      bad: "confidence: missing"

  - rule_id: ROI-003
    name: "Realistic ROI Expectations"
    severity: warning
    description: "Avoid overly optimistic ROI claims"
    check: |
      For each II# with roi_estimate:
      - If payback_period < 6 months, confidence should not be 'high' unless proven
      - Annual benefit should have supporting calculations
    remediation: "Validate ROI assumptions, avoid magical thinking"
    examples:
      good: "II#001: 6-9 month payback, confidence=high with details"
      bad: "II#996: 5 month payback, $500K benefit from $200K investment (unrealistic)"

  - rule_id: ROI-004
    name: "Quantified Benefits"
    severity: info
    description: "Benefits should be quantified when possible"
    check: |
      For each II# with roi_estimate:
      - annual_benefit includes specific numbers or ranges
      - Avoid vague benefits like "improved trust"
    remediation: "Quantify benefits (e.g., labor hours saved, error reduction %)"
    examples:
      good: "$180K labor savings + 30% error reduction"
      bad: "Improved trust and transparency"

# =============================================================================
# Traceability Requirements
# =============================================================================
traceability_rules:
  - rule_id: TRACE-001
    name: "Source Reference Required"
    severity: warning
    description: "Ideas should link to trends or pain points"
    check: |
      For each II#:
      - trend_refs is not empty
      - OR pain_point_refs is not empty
    remediation: "Link innovation ideas to market trends or pain points"
    examples:
      good: "II#001: trend_refs=[TR#001, TR#002], pain_point_refs=[PP#003]"
      bad: "II#999: no trend or pain point references"

  - rule_id: TRACE-002
    name: "Valid Reference Format"
    severity: error
    description: "All references must use correct ID format"
    check: |
      For each II# reference field:
      - trend_refs matches pattern: TR#[0-9]{3}
      - pain_point_refs matches pattern: PP#[0-9]{3}
      - enhancement_refs matches pattern: EI#[0-9]{3}
      - step_refs matches pattern: PS#[0-9]{3}
    remediation: "Use correct ID format (e.g., TR#001, PP#003)"
    examples:
      good: "trend_refs: [TR#001, TR#002]"
      bad: "trend_refs: [TR#1, TREND-001]"

  - rule_id: TRACE-003
    name: "Cross-Reference Validation"
    severity: error
    description: "Referenced IDs must exist in corresponding documents"
    check: |
      For each II# reference:
      - If trend_refs includes TR#XXX, TR#XXX exists in market_trends
      - If pain_point_refs includes PP#XXX, PP#XXX exists in PDA output
      - If enhancement_refs includes EI#XXX, EI#XXX exists in CJA output
      - If step_refs includes PS#XXX, PS#XXX exists in PDA output
    remediation: "Only reference valid IDs from other documents"
    examples:
      good: "II#001 → TR#001 (exists in market_trends)"
      bad: "II#001 → TR#999 (doesn't exist)"

  - rule_id: TRACE-004
    name: "Process Step Relevance"
    severity: info
    description: "Ideas should reference affected process steps"
    check: |
      For each II#:
      - If idea impacts specific steps, step_refs should be populated
    remediation: "Link ideas to process steps they will change"
    examples:
      good: "II#001 affects PS#003 (Document Collection)"
      bad: "No step references for operational improvement"

# =============================================================================
# Content Quality
# =============================================================================
content_rules:
  - rule_id: CONT-001
    name: "Specific Description Required"
    severity: error
    description: "Idea description must be specific, not vague"
    check: |
      For each II#:
      - description is not empty
      - description length > 100 characters
      - description includes WHAT, HOW, and expected outcome
    remediation: "Provide detailed description of the innovation"
    examples:
      good: "II#001: Multi-paragraph description with specifics"
      bad: "II#999: 'Make the loan process faster' (too vague)"

  - rule_id: CONT-002
    name: "Name Clarity"
    severity: warning
    description: "Idea name should be clear and descriptive"
    check: |
      For each II#:
      - name is not empty
      - name is not generic (e.g., "Improve Process", "Use AI")
      - name indicates the specific solution
    remediation: "Use descriptive names that indicate the solution"
    examples:
      good: "AI-Powered Document Verification"
      bad: "Improve Processing Time"

  - rule_id: CONT-003
    name: "Category Assignment"
    severity: error
    description: "Idea must have valid category"
    check: |
      For each II#:
      - category is one of:
        - process_automation
        - digital_transformation
        - customer_experience
        - cost_reduction
        - revenue_growth
        - compliance_enhancement
        - risk_mitigation
        - operational_efficiency
    remediation: "Assign appropriate category from schema"
    examples:
      good: "category: process_automation"
      bad: "category: operational_efficiency_improvement"

  - rule_id: CONT-004
    name: "Implementation Details"
    severity: warning
    description: "High-priority ideas should have implementation details"
    check: |
      For each II# with priority=must OR priority=should:
      - implementation.approach is defined
      - implementation.timeline is defined
      - implementation.risks is not empty
    remediation: "Provide implementation guidance for high-priority ideas"
    examples:
      good: "II#001: implementation with approach, timeline, risks"
      bad: "II#999: priority=must but no implementation details"

# =============================================================================
# Innovation Viability
# =============================================================================
viability_rules:
  - rule_id: VIAB-001
    name: "Problem-Driven Innovation"
    severity: warning
    description: "Ideas should solve real problems, not just use technology"
    check: |
      For each II#:
      - Has pain_point_refs OR clear problem statement in description
      - Not technology-driven without business justification
    remediation: "Ensure ideas address specific pain points or opportunities"
    examples:
      good: "II#001 addresses PP#003 (slow document verification)"
      bad: "II#998 uses blockchain but doesn't solve real problems"

  - rule_id: VIAB-002
    name: "Avoid Over-Engineering"
    severity: warning
    description: "Solutions should match problem scope"
    check: |
      For each II#:
      - If complexity=1 (very complex), verify commensurate value
      - Financial score should align with expected benefit
    remediation: "Consider simpler alternatives for smaller problems"
    examples:
      good: "II#001: Moderate complexity (3) for significant benefit"
      bad: "II#998: Blockchain for audit trail (database would suffice)"

  - rule_id: VIAB-003
    name: "Strategic Fit Defined"
    severity: info
    description: "Ideas should indicate strategic alignment"
    check: |
      For each II#:
      - strategic_fit is one of: core, adjacent, transformational
    remediation: "Classify ideas by strategic fit"
    examples:
      good: "strategic_fit: core"
      bad: "strategic_fit: missing"

  - rule_id: VIAB-004
    name: "Regulatory Consideration"
    severity: warning
    description: "Financial services ideas must consider regulation"
    check: |
      For each II# with regulatory score < 3:
      - Implementation should include compliance review
      - Risks should mention regulatory approval needed
    remediation: "Highlight regulatory considerations for low scores"
    examples:
      good: "II#002: regulatory=3, requires privacy compliance review"
      bad: "II#XXX: regulatory=2, no mention of compliance process"

# =============================================================================
# Completeness Checks
# =============================================================================
completeness_rules:
  - rule_id: COMP-001
    name: "Minimum Required Fields"
    severity: error
    description: "All required fields must be populated"
    check: |
      For each II#:
      - id matches pattern: II#[0-9]{3}
      - name is not empty
      - description is not empty
      - feasibility is complete (6 dimensions + weighted_score)
      - priority is assigned
    remediation: "Complete all required fields per innovation-schema.yaml"
    examples:
      good: "II#001: all required fields present"
      bad: "II#997: missing feasibility dimensions"

  - rule_id: COMP-002
    name: "Recommended Fields for High Priority"
    severity: warning
    description: "Must/Should ideas should have recommended fields"
    check: |
      For each II# with priority=must OR priority=should:
      - category is defined
      - strategic_fit is defined
      - roi_estimate is defined
      - trend_refs or pain_point_refs is not empty
      - implementation is defined
    remediation: "Complete recommended fields for high-priority ideas"
    examples:
      good: "II#001: all recommended fields present"
      bad: "II#999: priority=must but missing most recommended fields"

# =============================================================================
# Validation Severity Levels
# =============================================================================
severity_definitions:
  error:
    description: "Must be fixed before publishing"
    fail_validation: true
    examples:
      - "Missing required fields"
      - "Invalid ID format"
      - "Incomplete feasibility assessment"

  warning:
    description: "Should be addressed, validation passes with warnings"
    fail_validation: false
    examples:
      - "Priority-feasibility misalignment"
      - "Missing ROI for high-priority ideas"
      - "No trend/pain point references"

  info:
    description: "Suggestions for improvement"
    fail_validation: false
    examples:
      - "Strategic fit not defined"
      - "Consider adding implementation details"
      - "Opportunity for better documentation"

# =============================================================================
# Validation Report Template
# =============================================================================
report_template: |
  # Innovation Idea Validation Report

  **Process:** {process_name}
  **Document:** {document_path}
  **Validation Date:** {date}
  **Total Ideas:** {total_ideas}

  ## Summary

  | Category | Errors | Warnings | Info |
  |----------|--------|----------|------|
  | Feasibility | {feas_errors} | {feas_warnings} | {feas_info} |
  | Priority | {prio_errors} | {prio_warnings} | {prio_info} |
  | ROI | {roi_errors} | {roi_warnings} | {roi_info} |
  | Traceability | {trace_errors} | {trace_warnings} | {trace_info} |
  | Content | {cont_errors} | {cont_warnings} | {cont_info} |
  | Viability | {viab_errors} | {viab_warnings} | {viab_info} |
  | Completeness | {comp_errors} | {comp_warnings} | {comp_info} |
  | **TOTAL** | **{total_errors}** | **{total_warnings}** | **{total_info}** |

  **Overall Result:** {overall_result}

  ## Issues by Innovation Idea

  {issues_by_idea}

  ## Recommendations

  {recommendations}

  ## Next Steps

  - [ ] Fix all errors (blocking issues)
  - [ ] Review warnings and address critical ones
  - [ ] Consider info suggestions for quality improvement
  - [ ] Re-run validation after fixes

---

**See Also:**
- `innovation-idea-examples.md` - Good/bad example guidance
- `feasibility-scoring-examples.md` - Scoring methodology
- `innovation-schema.yaml` - Field definitions
